{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "611a344a-6f05-456b-bc12-144d248650c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search maths\n",
      "Total books found: 918\n",
      "search data science\n",
      "Total books found: 1678\n",
      "search English Literature\n",
      "Total books found: 2534\n",
      "search Python programming\n",
      "Total books found: 3289\n",
      "successfully inserted in book_data\n",
      "successfully inserted in authors_publishers\n",
      "successfully inserted in rating\n",
      "successfully inserted in price\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "api_key = \"Enter your API KEY\"   # API key\n",
    "def create_database_schema():\n",
    "    connection = mysql.connector.connect(\n",
    "    host = \"localhost\",\n",
    "    user = \"root\",\n",
    "    password = \"jeya\",\n",
    "    auth_plugin='mysql_native_password'\n",
    "\n",
    "    )\n",
    "\n",
    "    con = connection.cursor()\n",
    "    con.execute(\"CREATE DATABASE bookscape\")\n",
    "    connection.commit()\n",
    "    con.execute('use bookscape')\n",
    "    host = \"localhost\"\n",
    "    user = \"root\"\n",
    "    password = \"jeya\"\n",
    "    port = 3306\n",
    "    database_ip='127.0.0.1'\n",
    "    database = \"bookscape\"\n",
    "# Create a SQLAlchemy engine\n",
    "    my_conn = create_engine('mysql+pymysql://{0}:{1}@{2}:{3}/{4}'.format(user,password,host,port,database))\n",
    "\n",
    "    table_name = \"book_data\"\n",
    "# Load the DataFrame into the SQL database table 'book_data'\n",
    "    df2.to_sql(table_name,my_conn,if_exists=\"replace\",index=False) #['fail,replace,append']\n",
    "    print(\"successfully inserted in book_data\")\n",
    "    con.execute('alter table book_data modify column new_id varchar(100)')\n",
    "    #con.execute('alter table book_data add primary key(book_id)')\n",
    "    connection.commit()\n",
    "    #con.execute(\"update book_data set newid=concat(book_id,'+', search_key)\")\n",
    "    #connection.commit()\n",
    "    con.execute('alter table book_data add primary key(new_id)')  \n",
    "    connection.commit()\n",
    " # Load the DataFrame into the SQL database table 'authors_publishers'   \n",
    "    table_name = \"authors_publishers\"\n",
    "    df3.to_sql(table_name,my_conn,if_exists=\"replace\",index=False) #['fail,replace,append']\n",
    "    print(\"successfully inserted in authors_publishers\")\n",
    "    con.execute('alter table authors_publishers modify column new_id varchar(100)')\n",
    "    connection.commit() \n",
    "    con.execute('alter table authors_publishers add foreign key(new_id) references book_data(new_id)')\n",
    "    connection.commit()\n",
    "# Load the DataFrame into the SQL database table 'rating'   \n",
    "    table_name = \"rating\"\n",
    "    df4.to_sql(table_name,my_conn,if_exists=\"replace\",index=False) #['fail,replace,append']\n",
    "    print(\"successfully inserted in rating\")\n",
    "    con.execute('alter table rating modify column new_id varchar(100)')\n",
    "    connection.commit() \n",
    "    con.execute('alter table rating add foreign key(new_id) references book_data(new_id)')\n",
    "    connection.commit()   \n",
    "# Load the DataFrame into the SQL database table 'price'   \n",
    "    table_name = \"price\"\n",
    "    df5.to_sql(table_name,my_conn,if_exists=\"replace\",index=False) #['fail,replace,append']\n",
    "    print(\"successfully inserted in price\")\n",
    "    con.execute('alter table price modify column new_id varchar(100)')\n",
    "    connection.commit() \n",
    "    con.execute('alter table price add foreign key(new_id) references book_data(new_id)')\n",
    "    connection.commit() \n",
    "    con.close()\n",
    "def get_book_data(search_query, max_results=1000):\n",
    "    \"\"\"\n",
    "    Fetches book data from the Google Books API.\n",
    "\n",
    "    Args:\n",
    "        search_query: The search term for books.\n",
    "        max_results: The maximum number of results to retrieve (default is 5000).\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame containing book information, or None if an error occurs.\n",
    "    \"\"\"\n",
    "\n",
    "    base_url = \"https://www.googleapis.com/books/v1/volumes\"\n",
    "    params = {\n",
    "        \"q\": search_query,\n",
    "        \"key\": api_key,\n",
    "        \"maxResults\": 40\n",
    "    }\n",
    "\n",
    "    all_book_data = []\n",
    "    startIndex = 0\n",
    "    total_items = 0\n",
    "\n",
    "    try:\n",
    "        while startIndex < min(max_results, 1000) and (startIndex < total_items or total_items == 0):\n",
    "       # while startIndex <= max_results:\n",
    "            params[\"startIndex\"] = startIndex\n",
    "            #print('param',params)\n",
    "            response = requests.get(base_url, params=params)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "\n",
    "            if 'items' not in data:\n",
    "                #print(\"No items found in API response.\")\n",
    "                break\n",
    "\n",
    "            items = data['items']\n",
    "            #t(items)\n",
    "            total_items = data.get(\"totalItems\", 0)\n",
    "            #print('total',len(items))\n",
    "\n",
    "            for item in items:\n",
    "                volume_info = item.get('volumeInfo', {})\n",
    "                sale_info = item.get('saleInfo', {})\n",
    "\n",
    "                book_info = {\n",
    "                    'book_id': item.get('id', ''),\n",
    "                    'search_key': search_query,\n",
    "                    'book_title': volume_info.get('title', ''),\n",
    "                    'book_subtitle': volume_info.get('subtitle', ''),\n",
    "                    #'volume_id': volume_info.get('id', ''),\n",
    "                    'book_authors': \", \".join(volume_info.get('authors', [])),\n",
    "                    'book_description': volume_info.get('description', ''),\n",
    "                    'publisher': volume_info.get('publisher', ''),\n",
    "                    'industryIdentifiers': \", \".join([identifier.get('identifier', '') for identifier in volume_info.get('industryIdentifiers', [])]),\n",
    "                    'text_readingModes': volume_info.get('readingModes', {}).get('text', False),\n",
    "                    'image_readingModes': volume_info.get('readingModes', {}).get('image', False),\n",
    "                    'pageCount': volume_info.get('pageCount', 0),\n",
    "                    'categories': \", \".join(volume_info.get('categories', [])),\n",
    "                    'language': volume_info.get('language', ''),\n",
    "                    'imageLinks': str(volume_info.get('imageLinks', {})),\n",
    "                    'ratingsCount': volume_info.get('ratingsCount', 0),\n",
    "                    'averageRating': volume_info.get('averageRating', 0),\n",
    "                    'country': sale_info.get('country', ''),\n",
    "                    'saleability': sale_info.get('saleability', ''),\n",
    "                    'isEbook': sale_info.get('isEbook', False),\n",
    "                    'amount_listPrice': sale_info.get('listPrice', {}).get('amount', 0),\n",
    "                    'currencyCode_listPrice': sale_info.get('listPrice', {}).get('currencyCode', ''),\n",
    "                    'amount_retailPrice': sale_info.get('retailPrice', {}).get('amount', 0),\n",
    "                    'currencyCode_retailPrice': sale_info.get('retailPrice', {}).get('currencyCode', ''),\n",
    "                    'buyLink': sale_info.get('buyLink', ''),\n",
    "                    'year': volume_info.get('publishedDate', '').split('-')[0] if volume_info.get('publishedDate', '') else '',\n",
    "                    'new_id': item.get('id', '')+'+'+search_query\n",
    "\n",
    "                }\n",
    "               \n",
    "                all_book_data.append(book_info)\n",
    "\n",
    "\n",
    "            startIndex += 40\n",
    "\n",
    "        if not all_book_data:\n",
    "            print(\"No book data found for the search query.\")\n",
    "            return None\n",
    "        return pd.DataFrame(all_book_data)\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "df1=pd.DataFrame()\n",
    "search_term = [\"maths\",\"data science\",\"English Literature\",\"Python programming\"]\n",
    "#search_term=\"data science\"\n",
    "for i in search_term:\n",
    "    #if i == 'maths':\n",
    "    print('search',i)\n",
    "    df = get_book_data(i, max_results=1000)\n",
    "        #print(df)\n",
    "    if df is not None:\n",
    "        df1=pd.concat([df1,df],axis=0,ignore_index=True)\n",
    "        \n",
    "        print(f\"Total books found: {len(df1)}\")\n",
    "    \n",
    "if df1 is not None:  \n",
    "    \n",
    "    df1['averageRating']=df1['averageRating'].astype(float)\n",
    "    df1['ratingsCount']=df1['ratingsCount'].astype(float)\n",
    "    df1['amount_listPrice']=df1['amount_listPrice'].astype(float)\n",
    "    df1['amount_retailPrice']=df1['amount_retailPrice'].astype(float)\n",
    "    #print(df1.info())   \n",
    "    #print(df1.tail(10))\n",
    "    df1=df1.drop_duplicates(keep=False)\n",
    "    df2=df1.loc[:,['book_id','search_key','book_title','book_subtitle','book_description','industryIdentifiers','text_readingModes','image_readingModes','pageCount','categories','language','imageLinks','country','saleability','isEbook','buyLink','year','new_id']]\n",
    "    df3=df1.loc[:,['new_id','book_authors','publisher']]\n",
    "    df4=df1.loc[:,['new_id','ratingsCount','averageRating']]\n",
    "    df5=df1.loc[:,['new_id','amount_listPrice','currencyCode_listPrice','amount_retailPrice','currencyCode_retailPrice']]\n",
    "    create_database_schema() \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d75676-7c98-44a7-b855-62cde31398c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
